{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>LARGE_area</th>\n",
       "      <th>LARGE_compactness</th>\n",
       "      <th>LARGE_concave_points</th>\n",
       "      <th>LARGE_concavity</th>\n",
       "      <th>LARGE_fractal_dimension</th>\n",
       "      <th>LARGE_perimeter</th>\n",
       "      <th>LARGE_radius</th>\n",
       "      <th>LARGE_smoothness</th>\n",
       "      <th>...</th>\n",
       "      <th>concave_points</th>\n",
       "      <th>concavity</th>\n",
       "      <th>fractal_dimension</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>radius</th>\n",
       "      <th>alpha_scale</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>symmetry</th>\n",
       "      <th>texture</th>\n",
       "      <th>beta_scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>184.60</td>\n",
       "      <td>25.38</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>122.80</td>\n",
       "      <td>17.99</td>\n",
       "      <td>5533.419816</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>10.38</td>\n",
       "      <td>-16038.934558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>158.80</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>132.90</td>\n",
       "      <td>20.57</td>\n",
       "      <td>456.771688</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>17.77</td>\n",
       "      <td>3213.443571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>152.50</td>\n",
       "      <td>23.57</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>130.00</td>\n",
       "      <td>19.69</td>\n",
       "      <td>3019.115378</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>21.25</td>\n",
       "      <td>-1102.110142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301.0</td>\n",
       "      <td>M</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>98.87</td>\n",
       "      <td>14.91</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>77.58</td>\n",
       "      <td>11.42</td>\n",
       "      <td>11923.601650</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>20.38</td>\n",
       "      <td>-789.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>152.20</td>\n",
       "      <td>22.54</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>135.10</td>\n",
       "      <td>20.29</td>\n",
       "      <td>5340.182994</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>14.34</td>\n",
       "      <td>12086.452028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id diagnosis  LARGE_area  LARGE_compactness  LARGE_concave_points  \\\n",
       "0    842302.0         M      2019.0             0.6656                0.2654   \n",
       "1    842517.0         M      1956.0             0.1866                0.1860   \n",
       "2  84300903.0         M      1709.0             0.4245                0.2430   \n",
       "3  84348301.0         M       567.7             0.8663                0.2575   \n",
       "4  84358402.0         M      1575.0             0.2050                0.1625   \n",
       "\n",
       "   LARGE_concavity  LARGE_fractal_dimension  LARGE_perimeter  LARGE_radius  \\\n",
       "0           0.7119                  0.11890           184.60         25.38   \n",
       "1           0.2416                  0.08902           158.80         24.99   \n",
       "2           0.4504                  0.08758           152.50         23.57   \n",
       "3           0.6869                  0.17300            98.87         14.91   \n",
       "4           0.4000                  0.07678           152.20         22.54   \n",
       "\n",
       "   LARGE_smoothness  ...  concave_points  concavity  fractal_dimension  \\\n",
       "0            0.1622  ...         0.14710     0.3001            0.07871   \n",
       "1            0.1238  ...         0.07017     0.0869            0.05667   \n",
       "2            0.1444  ...         0.12790     0.1974            0.05999   \n",
       "3            0.2098  ...         0.10520     0.2414            0.09744   \n",
       "4            0.1374  ...         0.10430     0.1980            0.05883   \n",
       "\n",
       "   perimeter  radius   alpha_scale  smoothness  symmetry  texture  \\\n",
       "0     122.80   17.99   5533.419816     0.11840    0.2419    10.38   \n",
       "1     132.90   20.57    456.771688     0.08474    0.1812    17.77   \n",
       "2     130.00   19.69   3019.115378     0.10960    0.2069    21.25   \n",
       "3      77.58   11.42  11923.601650     0.14250    0.2597    20.38   \n",
       "4     135.10   20.29   5340.182994     0.10030    0.1809    14.34   \n",
       "\n",
       "     beta_scale  \n",
       "0 -16038.934558  \n",
       "1   3213.443571  \n",
       "2  -1102.110142  \n",
       "3   -789.415600  \n",
       "4  12086.452028  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(569, 34)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('cancer.csv', sep=';')\n",
    "display(df.head())\n",
    "display(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = df.iloc[:, 2:], df.iloc[:,1]\n",
    "\n",
    "display(y)\n",
    "display(np.count_nonzero(y == 'M'))\n",
    "display(np.count_nonzero(y == 'B'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6198830409356725"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_np = X.to_numpy()\n",
    "# y_np = y.to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values,y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "KN = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\").fit(X_train, y_train)\n",
    "\n",
    "KN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5369281045751634"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(KN, X_test, y_test, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5964912280701754"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(KN, X_test, y_test, cv=loo)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6019607843137256"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KN = KNeighborsClassifier(n_neighbors=10, metric=\"euclidean\").fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(KN, X_test, y_test, cv=10)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532163742690059"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "minmax_scaled = minmax.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(minmax_scaled,y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "KN = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\").fit(X_train, y_train)\n",
    "\n",
    "KN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LARGE_compactness\n",
      "LARGE_concave_points\n",
      "LARGE_fractal_dimension\n",
      "LARGE_radius\n",
      "LARGE_smoothness\n",
      "SD_concave_points\n",
      "SD_fractal_dimension\n",
      "compactness\n",
      "fractal_dimension\n",
      "smoothness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:457: UserWarning: X has feature names, but SequentialFeatureSelector was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
    "\n",
    "selector=SequentialFeatureSelector(knn, n_features_to_select=10 ,direction=\"forward\")\n",
    "selector.fit(X.values, y)\n",
    "list = selector.get_support()\n",
    "\n",
    "for i in range(len(list)):\n",
    "    if list[i]:\n",
    "        print(X.columns[i])\n",
    "\n",
    "X_t = selector.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9124183006535947"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "# KN = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\").fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(knn, X_test, y_test, cv=10)\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352941176470588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
    "\n",
    "selector = SequentialFeatureSelector(knn, n_features_to_select=10 ,direction=\"forward\")\n",
    "X_t = selector.fit_transform(minmax_scaled, y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_t, y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "scores = cross_val_score(knn, X_test, y_test, cv=10)\n",
    "display(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gustavnolgren/Desktop/DataMining/A4/A4.ipynb Cell 19\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gustavnolgren/Desktop/DataMining/A4/A4.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gustavnolgren/Desktop/DataMining/A4/A4.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gustavnolgren/Desktop/DataMining/A4/A4.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m X_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39;49mfit_transform(minmax_scaled)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/gustavnolgren/Desktop/DataMining/A4/A4.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pca\u001b[39m.\u001b[39mexplained_variance_ratio_\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:460\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    461\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    464\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_full(X, n_components)\n\u001b[1;32m    511\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_truncated(X, n_components, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_svd_solver)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:616\u001b[0m, in \u001b[0;36mPCA._fit_truncated\u001b[0;34m(self, X, n_components, svd_solver)\u001b[0m\n\u001b[1;32m    612\u001b[0m     U, Vt \u001b[39m=\u001b[39m svd_flip(U[:, ::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], Vt[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    614\u001b[0m \u001b[39melif\u001b[39;00m svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    615\u001b[0m     \u001b[39m# sign flipping is done inside\u001b[39;00m\n\u001b[0;32m--> 616\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m randomized_svd(\n\u001b[1;32m    617\u001b[0m         X,\n\u001b[1;32m    618\u001b[0m         n_components\u001b[39m=\u001b[39;49mn_components,\n\u001b[1;32m    619\u001b[0m         n_oversamples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_oversamples,\n\u001b[1;32m    620\u001b[0m         n_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miterated_power,\n\u001b[1;32m    621\u001b[0m         power_iteration_normalizer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpower_iteration_normalizer,\n\u001b[1;32m    622\u001b[0m         flip_sign\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    623\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[1;32m    626\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_samples_ \u001b[39m=\u001b[39m n_samples\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomponents_ \u001b[39m=\u001b[39m Vt\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/extmath.py:450\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mif\u001b[39;00m transpose:\n\u001b[1;32m    447\u001b[0m     \u001b[39m# this implementation is a bit faster with smaller shape[1]\u001b[39;00m\n\u001b[1;32m    448\u001b[0m     M \u001b[39m=\u001b[39m M\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 450\u001b[0m Q \u001b[39m=\u001b[39m randomized_range_finder(\n\u001b[1;32m    451\u001b[0m     M,\n\u001b[1;32m    452\u001b[0m     size\u001b[39m=\u001b[39;49mn_random,\n\u001b[1;32m    453\u001b[0m     n_iter\u001b[39m=\u001b[39;49mn_iter,\n\u001b[1;32m    454\u001b[0m     power_iteration_normalizer\u001b[39m=\u001b[39;49mpower_iteration_normalizer,\n\u001b[1;32m    455\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    456\u001b[0m )\n\u001b[1;32m    458\u001b[0m \u001b[39m# project M to the (k + p) dimensional space using the basis vectors\u001b[39;00m\n\u001b[1;32m    459\u001b[0m B \u001b[39m=\u001b[39m safe_sparse_dot(Q\u001b[39m.\u001b[39mT, M)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/sklearn/utils/extmath.py:278\u001b[0m, in \u001b[0;36mrandomized_range_finder\u001b[0;34m(A, size, n_iter, power_iteration_normalizer, random_state)\u001b[0m\n\u001b[1;32m    276\u001b[0m     Q \u001b[39m=\u001b[39m safe_sparse_dot(A\u001b[39m.\u001b[39mT, Q)\n\u001b[1;32m    277\u001b[0m \u001b[39melif\u001b[39;00m power_iteration_normalizer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLU\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 278\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mlu(safe_sparse_dot(A, Q), permute_l\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    279\u001b[0m     Q, _ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mlu(safe_sparse_dot(A\u001b[39m.\u001b[39mT, Q), permute_l\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    280\u001b[0m \u001b[39melif\u001b[39;00m power_iteration_normalizer \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mQR\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/scipy/linalg/_decomp_lu.py:313\u001b[0m, in \u001b[0;36mlu\u001b[0;34m(a, permute_l, overwrite_a, check_finite, p_indices)\u001b[0m\n\u001b[1;32m    311\u001b[0m     p \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(m, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)\n\u001b[1;32m    312\u001b[0m     u \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros([k, k], dtype\u001b[39m=\u001b[39ma1\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m--> 313\u001b[0m     lu_dispatcher(a1, u, p, permute_l)\n\u001b[1;32m    314\u001b[0m     P, L, U \u001b[39m=\u001b[39m (p, a1, u) \u001b[39mif\u001b[39;00m m \u001b[39m>\u001b[39m n \u001b[39melse\u001b[39;00m (p, u, a1)\n\u001b[1;32m    316\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Stacked array\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \n\u001b[1;32m    318\u001b[0m     \u001b[39m# Prepare the contiguous data holders\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_pca = pca.fit_transform(minmax_scaled)\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9411764705882353"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\").fit(X_train, y_train)\n",
    "# pca.score(X_test, y_test)\n",
    "cross_val_score(knn, X_test, y_test, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'n_neighbors': [i for i in range(1,20)]}\n",
    "knn_model = KNeighborsClassifier()\n",
    "classifier = GridSearchCV(knn_model, parameters)\n",
    "classifier.fit(X_pca,y)\n",
    "\n",
    "best_idx = np.argmax(classifier.cv_results_['mean_test_score'])\n",
    "classifier.cv_results_['params'][best_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph2.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values,y.values, test_size=0.3, random_state=0)\n",
    "\n",
    "decision_tree = tree.DecisionTreeClassifier(min_samples_leaf=20)\n",
    "\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "data = tree.export_graphviz(decision_tree, out_file=None)\n",
    "graph = graphviz.Source(data)\n",
    "graph.render(\"graph2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
